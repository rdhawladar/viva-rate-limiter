# Rate-Limited API Key Manager - Complete Architecture

## **High-Level Architecture**

```
┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐
│                 │     │                  │     │                 │
│  Client Apps    │────▶│   API Gateway    │────▶│  Rate Limiter   │
│                 │     │  (HTTP Server)   │     │   (Redis)       │
└─────────────────┘     └──────────────────┘     └─────────────────┘
                                │                         │
                                │                         │
                                ▼                         ▼
                        ┌──────────────────┐     ┌─────────────────┐
                        │                  │     │                 │
                        │   Core Service   │────▶│  Task Queue     │
                        │   (Business      │     │  (Asynq/Redis)  │
                        │    Logic)        │     └─────────────────┘
                        └──────────────────┘              │
                                │                         │
                                ▼                         ▼
                        ┌──────────────────┐     ┌─────────────────┐
                        │   Primary DB     │     │    Workers      │
                        │  (PostgreSQL)    │◀────│  - Analytics    │
                        └──────────────────┘     │  - Billing      │
                                │                │  - Alerts       │
                                ▼                │  - Security     │
                        ┌──────────────────┐     │  - Customer Svc │
                        │  Read Replicas   │     └─────────────────┘
                        │  (PostgreSQL)    │              │
                        └──────────────────┘              ▼
                                                 ┌─────────────────┐
                                                 │   Prometheus    │
                                                 │   (Metrics)     │
                                                 └─────────────────┘
```

## **Low-Level Architecture**

### **1. API Gateway Layer**
```
HTTP Endpoints:
├── /api/v1/keys
│   ├── POST   /create      → Create new API key
│   ├── GET    /list        → List all keys (admin)
│   ├── GET    /:keyId      → Get key details
│   ├── PUT    /:keyId      → Update rate limits
│   ├── DELETE /:keyId      → Revoke key
│   └── POST   /:keyId/rotate → Rotate key
│
├── /api/v1/usage
│   ├── GET    /:keyId/current  → Current usage stats
│   ├── GET    /:keyId/history  → Historical usage
│   └── GET    /:keyId/limits   → Check limits
│
└── /api/v1/validate
    └── POST   /             → Validate API key + check rate limit
```

### **2. Rate Limiting Layer (Redis)**
```
Redis Structure:
├── Rate Limit Counters (Sliding Window)
│   └── key:api_key_xxx:window:1234567890 → count
│
├── API Key Cache
│   └── key:metadata:api_key_xxx → {tier, limits, status}
│
├── Sharding (by key hash)
│   ├── Redis Node 1: Keys 0-33%
│   ├── Redis Node 2: Keys 34-66%
│   └── Redis Node 3: Keys 67-100%
│
├── Pub/Sub Channels
│   └── config_updates → Real-time limit changes
│
└── Event Tracking
    └── key:violations:api_key_xxx:daily → violation count per day
```

### **3. Database Schema**
```sql
-- Primary Database (Write)
├── api_keys
│   ├── id (UUID)
│   ├── key_hash (VARCHAR, indexed)
│   ├── name (VARCHAR)
│   ├── tier (ENUM: free, pro, enterprise)
│   ├── rate_limit (INT)
│   ├── rate_window (INT) -- seconds
│   ├── status (ENUM: active, suspended, revoked)
│   ├── created_at
│   └── updated_at
│
├── usage_logs (partitioned by date)
│   ├── id (BIGSERIAL)
│   ├── api_key_id (UUID)
│   ├── endpoint (VARCHAR)
│   ├── status_code (INT)
│   ├── response_time (INT)
│   ├── timestamp (TIMESTAMP)
│   └── metadata (JSONB)
│
├── billing_records
│   ├── id (UUID)
│   ├── api_key_id (UUID)
│   ├── period_start (DATE)
│   ├── period_end (DATE)
│   ├── total_requests (BIGINT)
│   ├── overage_requests (BIGINT)
│   └── amount (DECIMAL)
│
├── alerts
│   ├── id (UUID)
│   ├── api_key_id (UUID)
│   ├── alert_type (VARCHAR)
│   ├── threshold (INT)
│   ├── triggered_at (TIMESTAMP)
│   └── resolved_at (TIMESTAMP)
│
└── rate_limit_violations (partitioned by date)
    ├── id (BIGSERIAL)
    ├── event_id (UUID, unique)
    ├── api_key_id (UUID, indexed)
    ├── endpoint (VARCHAR)
    ├── method (VARCHAR)
    ├── client_ip (INET)
    ├── user_agent (TEXT)
    ├── limit_value (INT)
    ├── window_seconds (INT)
    ├── current_count (INT)
    ├── tier_type (VARCHAR)
    ├── is_repeated (BOOLEAN)
    ├── country (VARCHAR)
    ├── region (VARCHAR)
    ├── timestamp (TIMESTAMP, indexed)
    └── processed_at (TIMESTAMP)
```

### **4. Task Queue Structure (Asynq)**
```
Asynq Task Types & Queues:
├── Task Types
│   ├── "rate_limit:exceeded"   → Handle rate limit violations
│   ├── "usage:analytics"       → Process usage analytics  
│   ├── "billing:calculate"     → Calculate billing records
│   ├── "alert:check"          → Check alert thresholds
│   ├── "security:analyze"     → Analyze suspicious patterns
│   ├── "customer:outreach"    → Customer success notifications
│   ├── "key:rotate"           → Rotate API keys
│   ├── "audit:log"            → Audit trail logging
│   └── "notify:send"          → Send notifications
│
├── Queue Priority Mapping
│   ├── critical (priority: 10) → rate_limit:exceeded, alerts, security:analyze
│   ├── default  (priority: 5)  → analytics, billing, customer:outreach
│   └── low      (priority: 1)  → audit logs, key rotation
│
└── Task Options
    ├── MaxRetry: 3-5 (configurable per task)
    ├── Timeout: 30s-5m (based on task type)
    └── RetentionPeriod: 7 days
```

## **Tech Stack Details**

### **Core Technologies**
```yaml
Language: Go 1.21+
Web Framework: Gin (lightweight, fast)
ORM: GORM v2
Database: PostgreSQL 15
Cache: Redis 7 (with Redis Cluster)
Task Queue: Asynq (Redis-based)
Monitoring: Prometheus + Grafana
Configuration: Viper
Logging: Zap (structured logging)
Testing: Testify + Mockery
Load Testing: k6
Container: Docker + Docker Compose
```

### **Project Structure**
```
rate-limiter/
├── cmd/
│   ├── api/          # Main API server
│   └── worker/       # Background workers
│
├── internal/
│   ├── config/       # Viper configuration
│   ├── controllers/  # HTTP handlers
│   ├── services/     # Business logic
│   ├── repositories/ # Database access
│   ├── models/       # GORM models
│   ├── middleware/   # Auth, logging, etc.
│   ├── tasks/        # Asynq task handlers
│   ├── cache/        # Redis operations
│   └── metrics/      # Prometheus collectors
│
├── pkg/
│   ├── ratelimit/    # Rate limiting algorithms
│   ├── utils/        # Shared utilities
│   └── errors/       # Custom error types
│
├── migrations/       # Database migrations
├── scripts/          # Build/deploy scripts
├── docker/          # Dockerfiles
├── configs/         # Environment configs
│   ├── dev.yaml
│   ├── staging.yaml
│   └── prod.yaml
│
└── tests/
    ├── integration/
    ├── load/        # k6 scripts
    └── e2e/
```

### **Key Algorithms**

**1. Sliding Window Rate Limiter with Event Publishing**
```go
func (r *RedisRateLimiter) Allow(ctx context.Context, req *RateLimitRequest) (*RateLimitResult, error) {
    now := time.Now().Unix()
    windowStart := now - int64(req.Window.Seconds())
    key := fmt.Sprintf("rate_limit:%s:%d", req.APIKey, now/int64(req.Window.Seconds()))
    
    pipe := r.client.Pipeline()
    
    // Remove old entries
    pipe.ZRemRangeByScore(ctx, key, "0", strconv.FormatInt(windowStart, 10))
    
    // Count current window
    countCmd := pipe.ZCard(ctx, key)
    
    // Add current request
    pipe.ZAdd(ctx, key, redis.Z{
        Score: float64(now),
        Member: now,
    })
    
    // Set expiry
    pipe.Expire(ctx, key, req.Window)
    
    _, err := pipe.Exec(ctx)
    if err != nil {
        return nil, err
    }
    
    currentCount := countCmd.Val()
    allowed := currentCount <= int64(req.Limit)
    
    result := &RateLimitResult{
        Allowed:      allowed,
        Limit:        req.Limit,
        Remaining:    max(0, req.Limit-int(currentCount)),
        ResetTime:    time.Unix(now+int64(req.Window.Seconds()), 0),
        CurrentCount: int(currentCount),
    }
    
    // Publish violation event if rate limit exceeded
    if !allowed {
        go r.publishViolationEvent(ctx, req, result)
    }
    
    return result, nil
}

func (r *RedisRateLimiter) publishViolationEvent(ctx context.Context, req *RateLimitRequest, result *RateLimitResult) {
    event := &RateLimitViolationEvent{
        EventID:      uuid.New().String(),
        APIKeyID:     req.APIKey,
        Endpoint:     req.Endpoint,
        Method:       req.Method,
        ClientIP:     req.ClientIP,
        UserAgent:    req.UserAgent,
        Limit:        req.Limit,
        Window:       int(req.Window.Seconds()),
        CurrentCount: result.CurrentCount,
        TierType:     req.TierType,
        Timestamp:    time.Now(),
    }
    
    payload, _ := json.Marshal(event)
    task := asynq.NewTask("rate_limit:exceeded", payload,
        asynq.Queue("critical"),
        asynq.MaxRetry(3),
        asynq.Timeout(30*time.Second))
    
    r.taskClient.Enqueue(task)
}
```

**2. Consistent Hashing for Sharding**
```go
func (s *ShardedRedis) GetShard(key string) *redis.Client {
    hash := crc32.ChecksumIEEE([]byte(key))
    shardIndex := hash % uint32(len(s.shards))
    return s.shards[shardIndex]
}
```

**3. Asynq Task Processing**
```go
// Task creation
func (s *UsageService) ProcessUsageAsync(keyID string, usage UsageData) error {
    payload, _ := json.Marshal(usage)
    task := asynq.NewTask("usage:analytics", payload,
        asynq.Queue("default"),
        asynq.MaxRetry(3),
        asynq.Timeout(2*time.Minute))
    
    _, err := s.client.Enqueue(task)
    return err
}

// Task handler
func HandleUsageAnalytics(ctx context.Context, t *asynq.Task) error {
    var usage UsageData
    if err := json.Unmarshal(t.Payload(), &usage); err != nil {
        return fmt.Errorf("failed to unmarshal usage data: %w", err)
    }
    
    // Process analytics
    return s.analyticsRepo.ProcessUsage(ctx, usage)
}

// Worker configuration
mux := asynq.NewServeMux()
mux.HandleFunc("rate_limit:exceeded", HandleRateLimitViolation)
mux.HandleFunc("usage:analytics", HandleUsageAnalytics)
mux.HandleFunc("billing:calculate", HandleBillingCalculation)
mux.HandleFunc("alert:check", HandleAlertCheck)
mux.HandleFunc("security:analyze", HandleSecurityAnalysis)
mux.HandleFunc("customer:outreach", HandleCustomerOutreach)

server := asynq.NewServer(
    asynq.RedisClientOpt{Addr: redisAddr},
    asynq.Config{
        Concurrency: 20,
        Queues: map[string]int{
            "critical": 10,
            "default":  8,
            "low":      2,
        },
        StrictPriority: true,
    },
)
```

**4. Rate Limit Violation Event Handlers**
```go
// Main violation handler - orchestrates all violation responses
func HandleRateLimitViolation(ctx context.Context, t *asynq.Task) error {
    var event RateLimitViolationEvent
    if err := json.Unmarshal(t.Payload(), &event); err != nil {
        return fmt.Errorf("failed to unmarshal violation event: %w", err)
    }
    
    // Store violation record
    if err := storeViolationRecord(ctx, &event); err != nil {
        return fmt.Errorf("failed to store violation record: %w", err)
    }
    
    // Trigger downstream processes
    go triggerSecurityAnalysis(ctx, &event)
    go triggerCustomerOutreach(ctx, &event)
    go updateViolationMetrics(ctx, &event)
    
    return nil
}

// Security analysis for abuse detection
func HandleSecurityAnalysis(ctx context.Context, t *asynq.Task) error {
    var event RateLimitViolationEvent
    json.Unmarshal(t.Payload(), &event)
    
    // Check for repeated violations
    violationCount := getViolationCount(ctx, event.APIKeyID, 24*time.Hour)
    
    if violationCount > ABUSE_THRESHOLD {
        // Temporary suspension
        suspendAPIKey(ctx, event.APIKeyID, 1*time.Hour)
        
        // Alert security team
        alertSecurityTeam(ctx, event, violationCount)
    }
    
    // Update abuse scoring
    updateAbuseScore(ctx, event.ClientIP, event.APIKeyID)
    
    return nil
}

// Customer success outreach for legitimate users
func HandleCustomerOutreach(ctx context.Context, t *asynq.Task) error {
    var event RateLimitViolationEvent
    json.Unmarshal(t.Payload(), &event)
    
    customer := getCustomerByAPIKey(ctx, event.APIKeyID)
    
    // Check if customer should be contacted
    if shouldContactCustomer(ctx, customer, &event) {
        if customer.Tier == "free" {
            // Suggest tier upgrade
            sendUpgradeNotification(ctx, customer, &event)
        } else {
            // Notify about usage spike
            sendUsageAlert(ctx, customer, &event)
        }
    }
    
    return nil
}
```

### **Environment-Specific Configs**
```yaml
# dev.yaml
database:
  host: localhost
  replicas: []
  
redis:
  shards:
    - localhost:6379
  
ratelimit:
  default_limit: 1000
  default_window: 60

asynq:
  concurrency: 10
  queues:
    critical: 6
    default: 3
    low: 1
  strict_priority: true
  retention_period: "168h" # 7 days

violations:
  abuse_threshold: 50  # violations per 24h before suspension
  suspension_duration: "1h"
  customer_contact_threshold: 5  # violations before contacting customer
  repeat_violation_window: "24h"

# prod.yaml  
database:
  host: primary.db.prod
  replicas:
    - replica1.db.prod
    - replica2.db.prod
    
redis:
  shards:
    - redis-shard1.prod:6379
    - redis-shard2.prod:6379
    - redis-shard3.prod:6379
    
ratelimit:
  default_limit: 100
  default_window: 60

asynq:
  concurrency: 20
  queues:
    critical: 10
    default: 8
    low: 2
  strict_priority: true
  retention_period: "168h"
  healthcheck_interval: "15s"

violations:
  abuse_threshold: 25  # violations per 24h before suspension (stricter in prod)
  suspension_duration: "2h"
  customer_contact_threshold: 3  # violations before contacting customer
  repeat_violation_window: "24h"
  enable_geo_blocking: true
  max_violations_per_ip: 100
```

This architecture provides a production-ready, scalable API key management system that can handle millions of requests while maintaining sub-millisecond rate limit checks! 

Key architectural benefits:
• **Event-Driven Violation Handling**: Automatic security analysis, customer outreach, and abuse prevention
• **Asynq Integration**: Simpler operations with better Go integration using existing Redis infrastructure  
• **Multi-Service Reactions**: Rate limit violations trigger coordinated responses across analytics, security, and customer success
• **Real-Time Monitoring**: Comprehensive tracking of usage patterns and violation trends
• **Scalable Processing**: Priority-based task queues ensure critical violations are handled immediately